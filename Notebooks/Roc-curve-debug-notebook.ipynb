{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":127612,"sourceType":"datasetVersion","datasetId":64826}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Objective, Can you correctly classify the medical specialties based on the transcription text\n#Let us import all the necessary libraries\nimport os\nimport numpy as np  \nimport pandas as pd \nimport time\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport nltk\nimport re, string\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom nltk import word_tokenize, sent_tokenize\n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelBinarizer,LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:09:32.997757Z","iopub.execute_input":"2025-04-05T05:09:32.998128Z","iopub.status.idle":"2025-04-05T05:09:33.009877Z","shell.execute_reply.started":"2025-04-05T05:09:32.998097Z","shell.execute_reply":"2025-04-05T05:09:33.008378Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"! pip install nltk\nimport nltk\nfrom nltk.corpus import stopwords\n\n# Download the stopwords dataset if not already downloaded\nnltk.download('stopwords')\n\n# Use the stopwords\nstop_words = set(stopwords.words('english'))\n\n#EDA\ndata = pd.read_csv('/kaggle/input/medicaltranscriptions/mtsamples.csv')\nprint(data.columns)\n#data.head(5)\n\ndata.drop('Unnamed: 0',axis=1,inplace=True)\n\ndata.columns\n\n# a function to preprocess the data\ndef Preprocessing(text):\n    text = str(text)\n    text = text.lower()\n    text = re.sub(r'\\([^)]*\\)', '', text)\n    text = re.sub('\"','', text) \n    text = re.sub(r\"'s\\b\",\"\",text)\n    text = re.sub(\"[^a-zA-Z]\", \" \", text) \n    tokens = [w for w in text.split() if not w in stop_words]\n    long_words = [i for i in tokens if len(i)>=3]\n    return (\" \".join(long_words)).strip()\n\ndata['cleaned_transcription'] = data['transcription'].apply(Preprocessing)\n\nprint(data.columns)\n\n# creating feature vectors and target vector\ntranscripts = data.cleaned_transcription.values\nY = data.medical_specialty.values\n\n# label encode our categorical target variable\nle = LabelEncoder()\nY = le.fit_transform(Y)\n\nprint(Y)\n\n# function to create document-term matrix\ndef create_vec(strings):\n  #tf = TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(1,3))\n  tf = TfidfVectorizer(max_features = 6000, ngram_range=(1,3), min_df=5, max_df=0.9)\n  tf.fit(strings)\n  X = tf.fit_transform(strings)\n  return X\nvecs = create_vec(transcripts)# a function to preprocess the data\n\nprint(vecs)\n\n# applying SMOTE oversampling method to upsample minority class labels\nsm = SMOTE()\nx_res, y_res = sm.fit_resample(vecs,Y)\n\ndf = pd.DataFrame({\"class\":list(y_res)})\ndf.head()\n\ndf['class'].value_counts()\n\n# Splitting data into train:test by 80:20\nx_train, x_val, y_train, y_val = train_test_split(x_res, y_res, test_size=0.2, random_state = 42)\n\nx_train = x_train.toarray()\nprint('\\nTraining features shape: ',x_train.shape)\n\nx_val =x_val.toarray()\nprint('Test features shape:     ',x_val.shape)\n\n# a function to train and evaluate model\ndef train_model(model, x_train,x_val,y_train,y_val):\n  model.fit(x_train,y_train)\n  prediction = model.predict(x_val)\n  print('Accuracy',round(accuracy_score(prediction, y_test)*100, 0),'%')\n  return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:22:08.520161Z","iopub.execute_input":"2025-04-05T05:22:08.520703Z","iopub.status.idle":"2025-04-05T05:23:11.933458Z","shell.execute_reply.started":"2025-04-05T05:22:08.520664Z","shell.execute_reply":"2025-04-05T05:23:11.931892Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nIndex(['Unnamed: 0', 'description', 'medical_specialty', 'sample_name',\n       'transcription', 'keywords'],\n      dtype='object')\nIndex(['description', 'medical_specialty', 'sample_name', 'transcription',\n       'keywords', 'cleaned_transcription'],\n      dtype='object')\n[0 2 2 ... 0 0 0]\n  (0, 3314)\t0.09403042310250295\n  (0, 908)\t0.10238291501134683\n  (0, 4064)\t0.10735828324847223\n  (0, 3528)\t0.091052388350128\n  (0, 5987)\t0.07621250555094665\n  (0, 5176)\t0.1047122232206365\n  (0, 5408)\t0.10566288771279468\n  (0, 149)\t0.11042100614514046\n  (0, 2991)\t0.06482340517448347\n  (0, 5920)\t0.10599037032882767\n  (0, 5229)\t0.09315652072007759\n  (0, 3313)\t0.06423350875032413\n  (0, 907)\t0.09820037674998712\n  (0, 5455)\t0.1047122232206365\n  (0, 3296)\t0.10440537031218039\n  (0, 573)\t0.05168030582444491\n  (0, 4063)\t0.10735828324847223\n  (0, 5861)\t0.0747634135990948\n  (0, 151)\t0.07360172648053642\n  (0, 5854)\t0.09298634708829116\n  (0, 5588)\t0.08200989042390401\n  (0, 174)\t0.11084004932756628\n  (0, 1892)\t0.09120641885175639\n  (0, 5898)\t0.08717028374419306\n  (0, 3527)\t0.07578736671479172\n  :\t:\n  (4998, 79)\t0.03310517329269429\n  (4998, 5228)\t0.02673213154159433\n  (4998, 3309)\t0.03841668654064721\n  (4998, 899)\t0.03767971148513521\n  (4998, 3258)\t0.030741670737100674\n  (4998, 5919)\t0.016174158152263012\n  (4998, 5410)\t0.030052436908878065\n  (4998, 4114)\t0.0368050417802233\n  (4998, 563)\t0.02949637536394681\n  (4998, 4062)\t0.027825392998304294\n  (4998, 5858)\t0.02307072872379747\n  (4998, 1180)\t0.027500465692073536\n  (4998, 3126)\t0.018346654676785163\n  (4998, 5387)\t0.03506540324474103\n  (4998, 3125)\t0.028963880957733237\n  (4998, 3294)\t0.09085108995895466\n  (4998, 5865)\t0.02515691011576306\n  (4998, 168)\t0.03177543879497484\n  (4998, 5434)\t0.04728103885220099\n  (4998, 3713)\t0.038110681271199175\n  (4998, 5674)\t0.019326540899389292\n  (4998, 150)\t0.1300761559817671\n  (4998, 4109)\t0.027983860570771242\n  (4998, 3511)\t0.013328382208873297\n  (4998, 5975)\t0.013606780844194363\n\nTraining features shape:  (35296, 6000)\nTest features shape:      (8824, 6000)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#print(x_train)\n#print(type(x_train))\n#print(x_val)\n#print(type(x_val))\n#print(y_train)\n#print(type(y_train))\nprint(y_val)\nprint(type(y_val))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T06:02:21.646103Z","iopub.execute_input":"2025-04-05T06:02:21.646634Z","iopub.status.idle":"2025-04-05T06:02:21.653583Z","shell.execute_reply.started":"2025-04-05T06:02:21.646596Z","shell.execute_reply":"2025-04-05T06:02:21.652085Z"}},"outputs":[{"name":"stdout","text":"[ 0 16 35 ... 17  4  0]\n<class 'numpy.ndarray'>\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"__________________________________________________________________________________","metadata":{}},{"cell_type":"code","source":"# LR\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.model_selection import RandomizedSearchCV, cross_validate\nfrom sklearn.linear_model import LogisticRegression\n\n# Define the parameter distribution for hyperparameter tuning\nparam_dist = {\n    'C': [0.1, 1, 10],  # Regularization strength\n    'solver': ['liblinear', 'lbfgs', 'saga'],  # Solver to use for optimization\n    'max_iter': [100, 250, 500, 1000],  # Maximum number of iterations for the solvers\n    'penalty': ['l2', 'l1', 'elasticnet'],  # Regularization penalty\n    'multi_class': ['auto', 'ovr', 'multinomial'],  # Multi-class strategy\n    'fit_intercept': [True, False],  # Whether to include the intercept term\n    'class_weight': [None, 'balanced'],  # Weigh classes differently in imbalanced datasets\n    'tol': [1e-5, 1e-3],  # Tolerance for stopping criteria\n}\n\n# Logistic Regression classification model\nclassifier = LogisticRegression()\n\n# Set up RandomizedSearchCV for hyperparameter tuning with cross-validation\nrandom_search = RandomizedSearchCV(estimator=classifier, param_distributions=param_dist, \n                                   n_iter=10, cv=2, n_jobs=-1, verbose=1, scoring='accuracy', random_state=42)\n\n# Train the model with RandomizedSearchCV\nrandom_search.fit(x_train, y_train)\n\n# Print the best parameters and the best score found by RandomizedSearchCV\nprint(f\"Best parameters from RandomizedSearchCV: {random_search.best_params_}\")\nprint(f\"Best cross-validation score: {random_search.best_score_}\")\n\n# Use the best estimator found by RandomizedSearchCV\nbest_classifier = random_search.best_estimator_\n\n# Cross-validation results with the best model (2-fold cross-validation)\ncv_results = cross_validate(best_classifier, x_train, y_train, cv=2)\n\n# Print cross-validation results (accuracy, fit time, score time)\nprint(\"Cross-validation results: \", cv_results)\n\n# Logistic Regression classification report using the best model\nprediction = best_classifier.predict(x_val)\n\n# Print classification report (with the correct order for y_true and y_pred)\nprint('Classification report for Logistic Regression: \\n', classification_report(y_val, prediction, target_names=list(le.classes_), digits=4))\n\n# Confusion Matrix Logistic Regression\nconf_matrix = confusion_matrix(y_val, prediction)\n\n# Plotting the confusion matrix\nplt.figure(figsize=(17, 17))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\nplt.title('Confusion Matrix for Logistic Regression')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n\n# Compute TP, TN, FP, FN for a binary classification example (choose one class)\nTP = conf_matrix[1, 1]  # True Positive\nTN = conf_matrix[0, 0]  # True Negative\nFP = conf_matrix[0, 1]  # False Positive\nFN = conf_matrix[1, 0]  # False Negative\n\n# Print TP, TN, FP, FN\nprint(f\"True Positives (TP): {TP}\")\nprint(f\"True Negatives (TN): {TN}\")\nprint(f\"False Positives (FP): {FP}\")\nprint(f\"False Negatives (FN): {FN}\")\n\n# Calculate True Positive Rate (TPR) and False Positive Rate (FPR)\nTPR = TP / (TP + FN)  # Sensitivity, Recall\nFPR = FP / (FP + TN)  # 1 - Specificity\n\n# Print TPR and FPR\nprint(f\"True Positive Rate (TPR): {TPR}\")\nprint(f\"False Positive Rate (FPR): {FPR}\")\n\n# Binarize the true labels for multi-class ROC calculation\ny_val_bin = label_binarize(y_val, classes=np.unique(y_val))  # Binarize true labels\ny_score = best_classifier.predict_proba(x_val)  # Predicted probabilities\n\n# Compute micro-average ROC curve and AUC\nfpr, tpr, _ = roc_curve(y_val_bin.ravel(), y_score.ravel())\nroc_auc = auc(fpr, tpr)\n\n# Plot the ROC curve for micro-average\nplt.figure(figsize=(10, 10))\n\n# Plot micro-average ROC curve\nplt.plot(fpr, tpr, color='navy', lw=2, linestyle='-', label=f'Micro-average (AUC = {roc_auc:.2f})')\n\n# Plot diagonal line (random classifier)\nplt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve of Logistic Regression Model') \nplt.legend(loc='upper left', bbox_to_anchor=(1, 1))\nplt.show()\n\n# Print micro-average AUC\nprint(f'Micro-average AUC: {roc_auc:.2f}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# LR\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.model_selection import RandomizedSearchCV, cross_validate\nfrom sklearn.linear_model import LogisticRegression\n\n# Logistic Regression classification model\nclassifier = LogisticRegression()\n\n# Wrap the classifier with OneVsRestClassifier\novr_classifier = OneVsRestClassifier(classifier)\n\n# Define the parameter distribution for hyperparameter tuning\nparam_dist = {\n    'estimator__C': [0.1, 1, 10],  # Regularization strength\n    'estimator__solver': ['liblinear', 'lbfgs', 'saga'],  # Solver to use for optimization\n    'estimator__max_iter': [100, 250, 500, 1000],  # Maximum number of iterations for the solvers\n    'estimator__penalty': ['l2', 'l1', 'elasticnet'],  # Regularization penalty\n    'estimator__multi_class': ['auto', 'ovr', 'multinomial'],  # Multi-class strategy\n    'estimator__fit_intercept': [True, False],  # Whether to include the intercept term\n    'estimator__class_weight': [None, 'balanced'],  # Weigh classes differently in imbalanced datasets\n    'estimator__tol': [1e-5, 1e-3],  # Tolerance for stopping criteria\n}\n\n# Set up RandomizedSearchCV for hyperparameter tuning with cross-validation\nrandom_search = RandomizedSearchCV(estimator=classifier, param_distributions=param_dist, \n                                   n_iter=10, cv=2, n_jobs=-1, verbose=1, scoring='accuracy', random_state=42)\n\n# Train the model with RandomizedSearchCV\nrandom_search.fit(x_train, y_train)\n\n# Print the best parameters and the best score found by RandomizedSearchCV\nprint(f\"Best parameters from RandomizedSearchCV: {random_search.best_params_}\")\nprint(f\"Best cross-validation score: {random_search.best_score_}\")\n\n# Use the best estimator found by RandomizedSearchCV\nbest_classifier = random_search.best_estimator_\n\n# Cross-validation results with the best model (2-fold cross-validation)\ncv_results = cross_validate(best_classifier, x_train, y_train, cv=2)\n\n# Print cross-validation results (accuracy, fit time, score time)\nprint(\"Cross-validation results: \", cv_results)\n\n# Logistic Regression classification report using the best model\nprediction = best_classifier.predict(x_val)\n\n# Print classification report (with the correct order for y_true and y_pred)\nprint('Classification report for Logistic Regression: \\n', classification_report(y_val, prediction, target_names=list(le.classes_), digits=4))\n\n# Confusion Matrix Logistic Regression\nconf_matrix = confusion_matrix(y_val, prediction)\n\n# Plotting the confusion matrix\nplt.figure(figsize=(17, 17))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\nplt.title('Confusion Matrix for Logistic Regression')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n\n# Compute TP, TN, FP, FN for a binary classification example (choose one class)\nTP = conf_matrix[1, 1]  # True Positive\nTN = conf_matrix[0, 0]  # True Negative\nFP = conf_matrix[0, 1]  # False Positive\nFN = conf_matrix[1, 0]  # False Negative\n\n# Print TP, TN, FP, FN\nprint(f\"True Positives (TP): {TP}\")\nprint(f\"True Negatives (TN): {TN}\")\nprint(f\"False Positives (FP): {FP}\")\nprint(f\"False Negatives (FN): {FN}\")\n\n# Calculate True Positive Rate (TPR) and False Positive Rate (FPR)\nTPR = TP / (TP + FN)  # Sensitivity, Recall\nFPR = FP / (FP + TN)  # 1 - Specificity\n\n# Print TPR and FPR\nprint(f\"True Positive Rate (TPR): {TPR}\")\nprint(f\"False Positive Rate (FPR): {FPR}\")\n\n# Binarize the true labels for multi-class ROC calculation\ny_val_bin = label_binarize(y_val, classes=np.unique(y_val))  # Binarize true labels\ny_score = best_classifier.predict_proba(x_val)  # Predicted probabilities\n\n# Compute micro-average ROC curve and AUC\nfpr, tpr, _ = roc_curve(y_val_bin.ravel(), y_score.ravel())\nroc_auc = auc(fpr, tpr)\n\n# Plot the ROC curve for micro-average\nplt.figure(figsize=(10, 10))\n\n# Plot micro-average ROC curve\nplt.plot(fpr, tpr, color='navy', lw=2, linestyle='-', label=f'Micro-average (AUC = {roc_auc:.2f})')\n\n# Plot diagonal line (random classifier)\nplt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve of Logistic Regression Model') \nplt.legend(loc='upper left', bbox_to_anchor=(1, 1))\nplt.show()\n\n# Print micro-average AUC\nprint(f'Micro-average AUC: {roc_auc:.2f}')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}